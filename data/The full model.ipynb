{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d308f8c2-d58f-4ac3-9c96-c06967f097fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تحدث الآن...\n",
      "لم أتمكن من فهم الصوت.\n",
      "تحدث الآن...\n",
      "لقد قلت: ازيك يا جمال\n",
      "رد: الحمد لله، كيف حالك أنت؟\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لم أتمكن من فهم الصوت.\n",
      "تحدث الآن...\n",
      "لقد قلت: ازيك يا جمال يا معرص\n",
      "رد: الحمد لله، كيف حالك أنت؟\n",
      "تحدث الآن...\n",
      "لقد قلت: اهلا بك في بيتي\n",
      "لم أسمع اسمك، لا أستطيع التحدث.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لقد قلت: اهلا بك في بيتي\n",
      "لم أسمع اسمك، لا أستطيع التحدث.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لم أتمكن من فهم الصوت.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لم أتمكن من فهم الصوت.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لقد قلت: عناصر\n",
      "لم أسمع اسمك، لا أستطيع التحدث.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# تشغيل الروبوت في حلقة تفاعلية\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m listen_and_respond():\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m, in \u001b[0;36mlisten_and_respond\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mتحدث الآن...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# الاستماع إلى الصوت مع ضبط المهلة\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, phrase_time_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m     30\u001b[0m     text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mلقد قلت:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\speech_recognition\\__init__.py:465\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    463\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\speech_recognition\\__init__.py:535\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m buffer \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mread(source\u001b[38;5;241m.\u001b[39mCHUNK)\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    537\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\speech_recognition\\__init__.py:196\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyaudio_stream\u001b[38;5;241m.\u001b[39mread(size, exception_on_overflow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mread_stream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream, num_frames,\n\u001b[0;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import playsound\n",
    "import os\n",
    "\n",
    "\n",
    "user_name = \"جمال\"\n",
    "\n",
    "\n",
    "def speak_gtts(text, lang='ar'):\n",
    "    \"\"\"تحويل النص إلى صوت باستخدام Google TTS وتشغيله مباشرة\"\"\"\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(\"response.mp3\")  \n",
    "        playsound.playsound(\"response.mp3\") \n",
    "        os.remove(\"response.mp3\") \n",
    "    except Exception as e:\n",
    "        print(f\"حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: {e}\")\n",
    "\n",
    "# دالة للاستماع والتفاعل مع الصوت\n",
    "def listen_and_respond():\n",
    "    \"\"\"الاستماع لصوت المستخدم والرد بناءً على الكلمات المدخلة\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"تحدث الآن...\")\n",
    "\n",
    "        try:\n",
    "           \n",
    "            audio = recognizer.listen(source, timeout=10, phrase_time_limit=7)\n",
    "            text = recognizer.recognize_google(audio, language=\"ar\")\n",
    "            print(\"لقد قلت:\", text)\n",
    "\n",
    "            \n",
    "            if user_name in text:\n",
    "                \n",
    "                if \"ازيك\" in text or \"إزيك\" in text:\n",
    "                    response = \"الحمد لله، كيف حالك أنت؟\"\n",
    "                    print(\"رد:\", response)\n",
    "                    speak_gtts(response)  \n",
    "                elif \"مرحبا\" in text:\n",
    "                    response = \"مرحبًا! كيف يمكنني مساعدتك؟\"\n",
    "                    print(\"رد:\", response)\n",
    "                    speak_gtts(response)\n",
    "                elif \"وداعا\" in text or \"مع السلامة\" in text:\n",
    "                    response = \"مع السلامة! أتمنى لك يومًا سعيدًا.\"\n",
    "                    print(\"رد:\", response)\n",
    "                    speak_gtts(response)\n",
    "                    return False  \n",
    "                else:\n",
    "                    response = \"عذرًا، لم أفهم ما قلت. هل يمكنك التكرار؟\"\n",
    "                    print(\"رد:\", response)\n",
    "                    speak_gtts(response)\n",
    "            else:\n",
    "                print(\"لم أسمع اسمك، لا أستطيع التحدث.\")\n",
    "                speak_gtts(\"لم أسمع اسمك، لا أستطيع التحدث.\")\n",
    "                \n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"لم تبدأ التحدث في الوقت المحدد.\")\n",
    "            speak_gtts(\"لم تبدأ التحدث في الوقت المحدد.\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"لم أتمكن من فهم الصوت.\")\n",
    "            speak_gtts(\"لم أتمكن من فهم الصوت.\")\n",
    "        except sr.RequestError:\n",
    "            print(\"حدث خطأ في الاتصال بخدمة التعرف على الصوت.\")\n",
    "            speak_gtts(\"حدث خطأ في الاتصال بالخدمة.\")\n",
    "\n",
    "        return True \n",
    "\n",
    "while True:\n",
    "    if not listen_and_respond():\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aa64896-fc2f-4dab-9d0e-a5e03e0f63b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M L A\\AppData\\Local\\Temp\\ipykernel_6508\\4289432793.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  question = torch.tensor(question, dtype=torch.float32)\n",
      "C:\\Users\\M L A\\AppData\\Local\\Temp\\ipykernel_6508\\4289432793.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.8299\n",
      "Epoch [200/1000], Loss: 0.4157\n",
      "Epoch [300/1000], Loss: 0.6022\n",
      "Epoch [400/1000], Loss: 0.9926\n",
      "Epoch [500/1000], Loss: 0.6092\n",
      "Epoch [600/1000], Loss: 0.0003\n",
      "Epoch [700/1000], Loss: 0.3922\n",
      "Epoch [800/1000], Loss: 0.0003\n",
      "Epoch [900/1000], Loss: 0.0049\n",
      "Epoch [1000/1000], Loss: 0.0018\n",
      "تم حفظ النموذج كملف .pt\n",
      "أنا بخير، شكراً على سؤالك! كيف يمكنني مساعدتك اليوم؟\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(r\"C:\\Users\\M L A\\Desktop\\data\\data.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "questions = [item['input_text'] for item in data['responses']]\n",
    "answers = [item['response_text'] for item in data['responses']]\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(answers)\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=50)  \n",
    "question_vectors = vectorizer.fit_transform(questions).toarray()\n",
    "\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self, questions, labels):\n",
    "        self.questions = questions\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        label = self.labels[idx]\n",
    "        return question, label\n",
    "\n",
    "\n",
    "class ChatBotModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ChatBotModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "input_size = question_vectors.shape[1] \n",
    "hidden_size = 8\n",
    "output_size = len(set(encoded_labels))\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000\n",
    "\n",
    "# إعداد بيانات التدريب\n",
    "train_questions, test_questions, train_labels, test_labels = train_test_split(\n",
    "    question_vectors, encoded_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "train_data = ChatDataset(train_questions, train_labels)\n",
    "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "\n",
    "\n",
    "model = ChatBotModel(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for question, label in train_loader:\n",
    "       \n",
    "        question = torch.tensor(question, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "       \n",
    "        outputs = model(question)\n",
    "        loss = criterion(outputs, label)\n",
    "        \n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), r\"C:\\Users\\M L A\\Desktop\\data\\chatbot_model1.pt\")\n",
    "print(\"تم حفظ النموذج كملف .pt\")\n",
    "\n",
    "\n",
    "def predict_response(question):\n",
    "    model.eval()\n",
    "    question_vector = vectorizer.transform([question]).toarray()\n",
    "    question_tensor = torch.tensor(question_vector, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        output = model(question_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return label_encoder.inverse_transform([predicted.item()])[0]\n",
    "\n",
    "\n",
    "print(predict_response(\"كيف حالك؟\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab76bed-a170-4898-b6ca-7e9b789abe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M L A\\AppData\\Local\\Temp\\ipykernel_13492\\682354654.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(r\"C:\\Users\\M L A\\Desktop\\data\\chatbot_model1.pt\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تحدث الآن...\n",
      "لقد قلت: ازيك عامل ايه\n",
      "رد: لا أستطيع معرفة الوقت حالياً. لكن يمكنك التحقق من الساعة على جهازك.\n",
      "تحدث الآن...\n",
      "لقد قلت: انا مش عايز اعرف الوقت انا عايز اعرف انت عامل ايه\n",
      "رد: لا أستطيع معرفة الوقت حالياً. لكن يمكنك التحقق من الساعة على جهازك.\n",
      "تحدث الآن...\n",
      "لقد قلت: كيف حالك\n",
      "رد: أنا بخير، شكراً على سؤالك! كيف يمكنني مساعدتك اليوم؟\n",
      "تحدث الآن...\n",
      "لقد قلت: ممكن تقول لي اخبار عن الحياه\n",
      "رد: قال النبي صلى الله عليه وسلم: 'الحياء من الإيمان'. هذه المقولة تشير إلى أهمية الحياء كجزء من سلوك المسلم.\n",
      "تحدث الآن...\n",
      "لم أتمكن من فهم الصوت.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لقد قلت: ماذا تعرف\n",
      "رد: نعم، أستطيع مساعدتك في حل مسائل الرياضيات.\n",
      "تحدث الآن...\n",
      "لقد قلت: ما اسمك\n",
      "رد: انا روبوت  من عمل محمد المصري\n",
      "تحدث الآن...\n",
      "لقد قلت: ماذا\n",
      "رد: لا أستطيع معرفة الوقت حالياً. لكن يمكنك التحقق من الساعة على جهازك.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لم أتمكن من فهم الصوت.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لقد قلت: الحياه\n",
      "رد: لا أستطيع معرفة الوقت حالياً. لكن يمكنك التحقق من الساعة على جهازك.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لم أتمكن من فهم الصوت.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لم أتمكن من فهم الصوت.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n",
      "لم أتمكن من فهم الصوت.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: response.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: \n",
      "    Error 263 for command:\n",
      "        open response.mp3\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "تحدث الآن...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 93\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# تشغيل الروبوت في حلقة تفاعلية\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m listen_and_respond():\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 73\u001b[0m, in \u001b[0;36mlisten_and_respond\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, phrase_time_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m     text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mلقد قلت:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[0;32m     75\u001b[0m     response \u001b[38;5;241m=\u001b[39m predict_response(text)  \u001b[38;5;66;03m# استخدام النموذج لتحديد الرد\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\speech_recognition\\recognizers\\google.py:256\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[1;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[0;32m    251\u001b[0m request_builder \u001b[38;5;241m=\u001b[39m create_request_builder(\n\u001b[0;32m    252\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mendpoint, key\u001b[38;5;241m=\u001b[39mkey, language\u001b[38;5;241m=\u001b[39mlanguage, filter_level\u001b[38;5;241m=\u001b[39mpfilter\n\u001b[0;32m    253\u001b[0m )\n\u001b[0;32m    254\u001b[0m request \u001b[38;5;241m=\u001b[39m request_builder\u001b[38;5;241m.\u001b[39mbuild(audio_data)\n\u001b[1;32m--> 256\u001b[0m response_text \u001b[38;5;241m=\u001b[39m obtain_transcription(\n\u001b[0;32m    257\u001b[0m     request, timeout\u001b[38;5;241m=\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39moperation_timeout\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[0;32m    261\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[0;32m    262\u001b[0m )\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_parser\u001b[38;5;241m.\u001b[39mparse(response_text)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\speech_recognition\\recognizers\\google.py:215\u001b[0m, in \u001b[0;36mobtain_transcription\u001b[1;34m(request, timeout)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobtain_transcription\u001b[39m(request: Request, timeout: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 215\u001b[0m         response \u001b[38;5;241m=\u001b[39m urlopen(request, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecognition request failed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e\u001b[38;5;241m.\u001b[39mreason))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    512\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    514\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 515\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    518\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:532\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    531\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    533\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:1373\u001b[0m, in \u001b[0;36mHTTPHandler.http_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPConnection, req)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m-> 1348\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1350\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import playsound\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# تعريف نموذج الشبكة العصبية\n",
    "class ChatBotModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ChatBotModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# تحميل ملف البيانات (الذي يحتوي على الأسئلة والأجوبة)\n",
    "with open(r\"C:\\Users\\M L A\\Desktop\\data\\data.json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# إعداد المعالجة\n",
    "questions = [item['input_text'] for item in data['responses']]\n",
    "answers = [item['response_text'] for item in data['responses']]\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(answers)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=50)\n",
    "vectorizer.fit(questions)\n",
    "\n",
    "# تحميل النموذج المدرب\n",
    "input_size = 50  # عدد الميزات في الجمل\n",
    "hidden_size = 8  # حجم الطبقة المخفية\n",
    "output_size = len(set(encoded_labels))  # عدد الفئات المختلفة\n",
    "model = ChatBotModel(input_size, hidden_size, output_size)\n",
    "model.load_state_dict(torch.load(r\"C:\\Users\\M L A\\Desktop\\data\\chatbot_model1.pt\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# دالة لتحويل النص إلى صوت باستخدام gTTS\n",
    "def speak_gtts(text, lang='ar'):\n",
    "    \"\"\"تحويل النص إلى صوت وتشغيله باستخدام مكتبة gTTS\"\"\"\n",
    "    try:\n",
    "        tts = gTTS(text=text, lang=lang)\n",
    "        tts.save(\"response.mp3\")  # حفظ الملف الصوتي مؤقتًا\n",
    "        playsound.playsound(\"response.mp3\")  # تشغيل الملف الصوتي\n",
    "        os.remove(\"response.mp3\")  # حذف الملف بعد تشغيله\n",
    "    except Exception as e:\n",
    "        print(f\"حدث خطأ أثناء تحويل النص إلى صوت باستخدام gTTS: {e}\")\n",
    "\n",
    "# دالة للتنبؤ بالرد باستخدام النموذج\n",
    "def predict_response(question):\n",
    "    \"\"\"استخدام النموذج المدرب للتنبؤ بالرد بناءً على السؤال\"\"\"\n",
    "    question_vector = vectorizer.transform([question]).toarray()\n",
    "    question_tensor = torch.tensor(question_vector, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        output = model(question_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return label_encoder.inverse_transform([predicted.item()])[0]\n",
    "\n",
    "# دالة للاستماع والرد\n",
    "def listen_and_respond():\n",
    "    \"\"\"الاستماع لصوت المستخدم وتحويله إلى نص والرد بناءً عليه\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"تحدث الآن...\")\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=10, phrase_time_limit=7)\n",
    "            text = recognizer.recognize_google(audio, language=\"ar\")\n",
    "            print(\"لقد قلت:\", text)\n",
    "            response = predict_response(text)  # استخدام النموذج لتحديد الرد\n",
    "            print(\"رد:\", response)\n",
    "            speak_gtts(response)  # تحويل الرد إلى صوت\n",
    "                \n",
    "        except sr.WaitTimeoutError:\n",
    "            print(\"لم تبدأ التحدث في الوقت المحدد.\")\n",
    "            speak_gtts(\"لم تبدأ التحدث في الوقت المحدد.\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"لم أتمكن من فهم الصوت.\")\n",
    "            speak_gtts(\"لم أتمكن من فهم الصوت.\")\n",
    "        except sr.RequestError:\n",
    "            print(\"حدث خطأ في الاتصال بخدمة التعرف على الصوت.\")\n",
    "            speak_gtts(\"حدث خطأ في الاتصال بالخدمة.\")\n",
    "\n",
    "        return True  # الاستمرار في الاستماع بعد الرد\n",
    "\n",
    "# تشغيل الروبوت في حلقة تفاعلية\n",
    "while True:\n",
    "    if not listen_and_respond():\n",
    "        break  # إنهاء البرنامج عند وداع المستخدم\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fda98-3aac-4fe0-9857-522ac2d41ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
